{"cells":[{"cell_type":"markdown","metadata":{"id":"u8vwRIunRWa_"},"source":["# Dimensionality reduction analysis\n","\n","After applying the different clustering algorithms, we now look at ways to improve the obtained results. One way to do so is by applying dimension reduction techniques such as Principal Component Analysis (PCA) and Canonical Correlation Analysis (CCA).\n","\n","\n","**<font color='red'>PCA:</font>** This method is used to reduced the dimensions of the data. In fact, sometimes we have variables that do not give any information about the data and thus removing these variables can lead to better results.  \n","\n","**<font color='red'>CCA:</font>** This method is used to detect correlations between different subgroups of data. In fact, sometimes we have variables that are so strongly correlated that reducing the dimensions using linear combinations between the correlated variables can imporove the results\n","It is **important to note that we will NOT use the labels when applying PCA and CCA.**\n","\n","___\n","\n","\n","Therefore, in this part of the project, you will apply both PCA and CCA on the data you chose in the clustering part. Afterwards, you will apply the clustering method that gave the best results in TD2_3 on the reduced dataset you obtained from the PCA step."]},{"cell_type":"markdown","metadata":{"id":"OmlK7xfGe0yw"},"source":["## Mount Drive\n","\n","**For google colab users only**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CFAM84Me9dB"},"outputs":[],"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","# Change to the directory to where your files are\n","os.chdir('drive/My Drive/')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LOkk8MDZRWbA"},"source":["## Import Libraries\n","\n","**Tip**: look at the documentation of the packages and methods imported, they can help you answer some questions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zMzYC9t-egB5"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","%matplotlib inline\n"]},{"cell_type":"markdown","metadata":{"id":"NbbEEnkpRWbE"},"source":["## Load the dataset, separate data from classes\n"]},{"cell_type":"markdown","metadata":{"id":"TmHQPPWoRWbE"},"source":["\n","Load the dataset you are using in your project and separate the data from the class.\n","\n","**<font color='red'>N.B:</font>** If you have applied some preprocessing steps (missing value replacement, factorize), please used the dataset you obtained after all the steps (you should have saved your dataset in notebook TD2_3.ipynb) without the normalization step.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GyoTiPLYOQ4j"},"outputs":[],"source":["df = pd.read_csv(\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9V7d9EmkImU"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"cvq_mI8UegDv"},"source":["## Part 1: Apply PCA"]},{"cell_type":"markdown","metadata":{"id":"ff-kMt84TrEJ"},"source":["\n","##### We start by scaling the data so that each feature has a single unit variance.  \n","\n","\n","**<font color='red'>N.B:</font>** For the purpose of this part of the project, we will scale both continuous and numerical variables.\n","PCA is designed for continuous variables, so theoretically you should only apply it to the data that was already continuous in your original dataset. To make this project easier and more comparable between groups, we have decided to let you apply it on all features."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTJ8zfTpegDw"},"outputs":[],"source":["# Use StandardScaler"]},{"cell_type":"markdown","metadata":{"id":"6LyNt_7cfnzT"},"source":["\n","##### We then instantiate a PCA object.\n","\n","The main parameter of this method is the max number of components. In this project, we will choose it to be equal to the max number of variables in the data.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yinJmteEegD1"},"outputs":[],"source":["\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P9rhEC4qRWb6"},"source":["### Interpreting the components\n","\n","The next step is to choose the number of components to keep."]},{"cell_type":"markdown","metadata":{"id":"dyAaYjVFTlT7"},"source":["##### Plot the explained variance of each component using the corrected variance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_d-KWKTPegEB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmWJ-PM6egEF"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"M9yAYZd5j1ti"},"source":["##### Plot the cumulative variance of the components based on the explained variance ratio."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVl7HvPnfGTX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zab8xcV6fGWi"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"E2X5QPscllr_"},"source":["##### How many components will you keep? Explain your choice."]},{"cell_type":"markdown","metadata":{"id":"DBsLf74ATgUR"},"source":[]},{"cell_type":"markdown","metadata":{"id":"4EX8NeBIr-cF"},"source":["**Note:** If you do choose to keep all components in your analysis, you do not perform any dimension reduction."]},{"cell_type":"markdown","metadata":{"id":"qytRrmdZvO89"},"source":["##### Create your reduced dimensionality dataset by only keeping the components you chose to keep in the above question."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Wkz9YhevcUT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"l4Wci1C9tA7Q"},"source":["##### What is the inertia percentage explained by the components you kept *(le pourcentage d’inertie expliquée par le premier axe factoriel)*?\n","\n","What does it mean?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4AFOlRFDs_3B"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZxdK5OpztILk"},"source":[]},{"cell_type":"markdown","metadata":{"id":"2Q-G866qtI0R"},"source":["##### Calculate the contribution of the first individual to the first component *(la contribution du premier individu au premier axe factoriel)*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mM2Zh_YItWxq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"egUNHUaztW6y"},"source":[]},{"cell_type":"markdown","metadata":{"id":"D2BTTizXtXIG"},"source":["##### Calculate the quality of representation of this individual in the map made of the first factorial axis *(la qualité de représentation de cet individu dans le plan constitué du premier axe factoriel)*.\n","\n","What can you deduce?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jm4TFfkcTLBZ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"exdvwVkMTMhD"},"source":[]},{"cell_type":"markdown","metadata":{"id":"qNPawU-kRWcB"},"source":["### Variable representation"]},{"cell_type":"markdown","metadata":{"id":"NDgtw_pdpnRN"},"source":["#### Compute the correlation between the principal components and the variables"]},{"cell_type":"markdown","metadata":{"id":"I9qpisnLS9hv"},"source":["##### Print the correlation matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyVN383MegEQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mj5h-7-6TB3S"},"source":["##### Plot the correlation circle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZVt9bAoegEU"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Tz6BAESnTEYt"},"source":["##### Interpret the obtained results"]},{"cell_type":"markdown","metadata":{"id":"v2M4KXLUTHYE"},"source":[]},{"cell_type":"markdown","metadata":{"id":"Wco8XUCXum56"},"source":["## Applying clustering on the newly created dataset."]},{"cell_type":"markdown","metadata":{"id":"g6nBalYFutE7"},"source":["Recall in TD2_3.ipynb, you applied different clustering algorithms on your dataset and analyzed which method gave the best results on your dataset."]},{"cell_type":"markdown","metadata":{"id":"UjpCWeLnS1qt"},"source":["##### Apply this clustering method to the dataset you obtained after applying PCA and performing dimension reduction."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zc6KNBeusTt"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7rMQH3J7vwB0"},"source":["##### Using the same metrics you used in TD2_3.ipynb, compare the results obtained with this method to the real classes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7gU4nZzv77M"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38QpAQtZv8gm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0_bYM4sv9Jt"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"rhze0hqxv-YD"},"source":["##### In your opinion, did dimensionality reduction help you in getting better results or not?"]},{"cell_type":"markdown","metadata":{"id":"uk5jlzG_wJnr"},"source":[]},{"cell_type":"markdown","metadata":{"id":"l0AlAlgJwTkI"},"source":["## Part 2: Apply CCA\n","\n","Next steps:\n","   - Apply CCA /!\\ Don't forget to split the dataset into two groups,i.e., p=3 and q=3\n","   - Analyze the correlation circle *(graphe des variables)*\n","   - Analyze the observation graph *(graphe des individus)*\n","\n","**<font color='red'>N.B:</font>** For the purpose of this part of the project, we will scale use continuous and numerical variables.\n","CCA is designed for continuous variables, so theoretically you should only apply it to the data that was already continuous in your original dataset. To make this project easier and more comparable between groups, we have decided to let you apply it on all features."]},{"cell_type":"markdown","metadata":{"id":"WJeqzQ9HPaIc"},"source":["### Choice of the two groups"]},{"cell_type":"markdown","metadata":{"id":"V3MXv0b6Mad7"},"source":["##### Show the correlation matrix of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxI6BPldMZ9S"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yIyGmn6AK_MQ"},"source":["##### Split your data into two groups p and q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BP23DikuwV15"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XfQA05BpSqAp"},"source":["##### How did you choose your two groups?"]},{"cell_type":"markdown","metadata":{"id":"kycWlA1SSuc7"},"source":[]},{"cell_type":"markdown","metadata":{"id":"7pcAD6c6NV6P"},"source":["### Apply CCA\n","\n","CCA with scikit-learn uses a very similar process to other preprocessing functions that come with scikit-learn. We instantiate a CCA object, find the  components (linear combinations of the variables) using the fit method, then apply the dimensionality reduction by calling transform().\n","\n","We can also specify how many components we want to keep when creating the CCA object."]},{"cell_type":"markdown","metadata":{"id":"37xi_b3xLj56"},"source":["Check the scikit-learn documentation for CCA. Do you need to use the scaled or unscaled data to apply CCA?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YaTi6tP8NVXA"},"source":[]},{"cell_type":"markdown","metadata":{"id":"Gg-dRL7TPolS"},"source":["##### Apply CCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBSdOeZqLm2I"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"IbUX-Ya1SaDM"},"source":["##### Print the first two components"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkgLEoMqLnQe"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0WBji3JxLoKg"},"source":["##### Print the correlation matrix between the first two components"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4iNLaVLdOh7T"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xGZrj19SOinb"},"source":["##### What can you conclude?"]},{"cell_type":"markdown","metadata":{"id":"yfBxyH2ZOt-S"},"source":[]},{"cell_type":"markdown","metadata":{"id":"-NqYbPUGOuw8"},"source":["### Results visualization and interpretation"]},{"cell_type":"markdown","metadata":{"id":"d0UK2piZQyGE"},"source":["#### Variable representation"]},{"cell_type":"markdown","metadata":{"id":"Pn9WxgzEOuzp"},"source":["##### Compute the correlation between the components and the variables\n","\n","[*aide: utiliser les matrices centrées-réduites*]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEtx_RR-OtN6"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"3TyeiIckQGQf"},"source":["##### Show the correlation circle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vdbaq7NQH4K"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"PZGdyIqWQJ5i"},"source":["##### Interpret the obtained results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuuRGz7wQQHK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ihkUgZJbQ24U"},"source":["#### Individual visualization"]},{"cell_type":"markdown","metadata":{"id":"r0ktU43JSLye"},"source":["##### Show the individuals representation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q5rTCInGQ6Ou"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"CEdCLoCfRkJA"},"source":["##### Interpret the obtained results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNrE4hjZRpaR"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"taYmgfN46Hf3"},"source":["### CCA Conclusion\n","Based on your visualizations, do you think it would be useful to use the CCA results to reduce the dimensionality of your dataset before applying some form of clustering method, like you did with PCA? Why / why not?"]},{"cell_type":"markdown","metadata":{"id":"bxVNPtXm6H2B"},"source":[]}],"metadata":{"celltoolbar":"Raw Cell Format","colab":{"collapsed_sections":["ff-kMt84TrEJ"],"provenance":[{"file_id":"1hd6m2nlCRdIuArnviwQApwLuQzwUVQqe","timestamp":1569178204442}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":0}
